{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('D:/Objective 1 code/classification/crop_queryTypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Crop_QueryType column into a list of values\n",
    "df['Crop_QueryType_List'] = df['Crop_QueryType'].str.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a feature matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "crop_querytype_matrix = mlb.fit_transform(df['Crop_QueryType_List'])\n",
    "\n",
    "# Convert the matrix to a DataFrame for better readability\n",
    "crop_querytype_df = pd.DataFrame(crop_querytype_matrix, columns=mlb.classes_)\n",
    "\n",
    "# Add Month and Place to the feature matrix\n",
    "crop_querytype_df['Month'] = df['Month']\n",
    "crop_querytype_df['Place'] = df['Place']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Place and Month, then aggregate the Crop_QueryType frequencies\n",
    "place_month_features = crop_querytype_df.groupby(['Place', 'Month']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Place and Month for clustering\n",
    "place_features = place_month_features.drop(columns=['Place', 'Month'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(place_features)\n",
    "\n",
    "# Step 5: Apply Spectral Clustering\n",
    "# Choose the number of clusters (e.g., 5)\n",
    "n_clusters = 5\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Assuming n_clusters is defined and X_scaled is your scaled data\n",
    "agglo = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "\n",
    "# Fit the model and get the cluster labels for each sample\n",
    "labels = agglo.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "place_month_features['Cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Analyze Clusters\n",
    "# Function to get the Crop_QueryType with maximum occurrence and list of places in each cluster\n",
    "def analyze_clusters(cluster_data, crop_querytype_df, top_n=10):\n",
    "    cluster_results = {}\n",
    "    for cluster in cluster_data['Cluster'].unique():\n",
    "        cluster_subset = cluster_data[cluster_data['Cluster'] == cluster]\n",
    "        \n",
    "        # Get the top 10 Crop_QueryTypes in the cluster\n",
    "        crop_querytype_counts = cluster_subset.drop(columns=['Place', 'Month', 'Cluster']).sum()\n",
    "        top_crop_querytypes = crop_querytype_counts.sort_values(ascending=False).head(top_n).to_dict()\n",
    "        \n",
    "        # Get the list of places in the cluster\n",
    "        places_in_cluster = cluster_subset['Place'].unique().tolist()\n",
    "        \n",
    "        # Store results\n",
    "        cluster_results[cluster] = {\n",
    "            'Top_Crop_QueryTypes': top_crop_querytypes,\n",
    "            'Places': places_in_cluster\n",
    "        }\n",
    "    return cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters\n",
    "cluster_results = analyze_clusters(place_month_features, crop_querytype_df, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Print the results\n",
    "for cluster, result in cluster_results.items():\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(\"  Top 10 Crop_QueryTypes:\")\n",
    "    for crop_querytype, count in result['Top_Crop_QueryTypes'].items():\n",
    "        print(crop_querytype)\n",
    "    print(\"\\n\")    \n",
    "    print(\"  Places in the cluster:\")\n",
    "    print(f\"    {result['Places']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def analyze_clusters(cluster_data, crop_querytype_df):\n",
    "    # For the first CSV: Month, Cluster, Crop_QueryType (without count)\n",
    "    crop_querytype_results = []\n",
    "    \n",
    "    # For the second CSV: Places, Cluster, Most_Common_State (not month-wise)\n",
    "    place_results = []\n",
    "    \n",
    "    # Extract states from places (StateName_DistrictName)\n",
    "    cluster_data['State'] = cluster_data['Place'].str.split('_').str[0]\n",
    "    \n",
    "    # Group by Cluster to find most common state and places\n",
    "    for cluster in cluster_data['Cluster'].unique():\n",
    "        cluster_subset = cluster_data[cluster_data['Cluster'] == cluster]\n",
    "        \n",
    "        # Get the most common state in the cluster\n",
    "        most_common_state = Counter(cluster_subset['State']).most_common(25)\n",
    "        \n",
    "        # Get the list of places in the cluster\n",
    "        places_in_cluster = cluster_subset['Place'].unique().tolist()\n",
    "        \n",
    "        # Add results to the place_results list\n",
    "        place_results.append({\n",
    "            'Cluster': int(cluster),\n",
    "            'Most_Common_State': most_common_state,\n",
    "            'Places': ', '.join(places_in_cluster)\n",
    "        })\n",
    "    \n",
    "    # Group by Month and Cluster to find top Crop_QueryTypes\n",
    "    for month in cluster_data['Month'].unique():\n",
    "        month_subset = cluster_data[cluster_data['Month'] == month]\n",
    "        for cluster in month_subset['Cluster'].unique():\n",
    "            cluster_subset = month_subset[month_subset['Cluster'] == cluster]\n",
    "            \n",
    "            # Get the top 5 Crop_QueryTypes in the cluster for this month\n",
    "            crop_querytype_counts = cluster_subset.drop(columns=['Place', 'Month', 'Cluster', 'State']).sum()\n",
    "            top_crop_querytypes = crop_querytype_counts.sort_values(ascending=False).head(5)\n",
    "            crop_querytypes = ', '.join(top_crop_querytypes.index.tolist())\n",
    "            # Add results to the crop_querytype_results list\n",
    "            for crop_querytype in top_crop_querytypes.index:\n",
    "                crop_querytype_results.append({\n",
    "                    'Month': int(month),\n",
    "                    'Cluster': int(cluster),\n",
    "                    'Crop_QueryType': crop_querytypes\n",
    "                })\n",
    "    \n",
    "    return crop_querytype_results, place_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_querytype_results, place_results = analyze_clusters(place_month_features, crop_querytype_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_querytype_df = pd.DataFrame(crop_querytype_results)\n",
    "crop_querytype_df=crop_querytype_df.drop_duplicates()\n",
    "print(crop_querytype_df)\n",
    "crop_querytype_df.to_csv('D:/Objective 1 code/crop_querytype.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second CSV: Places, Cluster, Most_Common_State\n",
    "place_df = pd.DataFrame(place_results)\n",
    "\n",
    "place_df.to_csv(\"D:/Objective 1 code/place_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Calculate Mode Cluster for Each Place\n",
    "def calculate_mode_cluster(cluster_data):\n",
    "    mode_cluster_results = []\n",
    "    \n",
    "    # Group by Place and calculate the mode cluster\n",
    "    for place in cluster_data['Place'].unique():\n",
    "        place_subset = cluster_data[cluster_data['Place'] == place]\n",
    "        \n",
    "        # Get the mode cluster for this place\n",
    "        mode_cluster = Counter(place_subset['Cluster']).most_common(1)[0][0]\n",
    "        \n",
    "        # Add results to the mode_cluster_results list\n",
    "        mode_cluster_results.append({\n",
    "            'Place': place,\n",
    "            'Mode_Cluster': int(mode_cluster)\n",
    "        })\n",
    "    \n",
    "    return mode_cluster_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mode cluster for each place\n",
    "mode_cluster_results = calculate_mode_cluster(place_month_features)\n",
    "cluster_places=pd.DataFrame(mode_cluster_results)\n",
    "print(cluster_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_places.to_csv(\"D:/Objective 1 code/places_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# Step 1: Extract features and cluster labels\n",
    "X = place_features  # Feature matrix (without Place and Month)\n",
    "labels = place_month_features['Cluster']  # Cluster labels\n",
    "\n",
    "# Step 2: Calculate evaluation metrics\n",
    "# Silhouette Score\n",
    "silhouette_avg = silhouette_score(X, labels)\n",
    "print(f\"Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# Calinski-Harabasz Index\n",
    "calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "print(f\"Calinski-Harabasz Index: {calinski_harabasz}\")\n",
    "\n",
    "# Davies-Bouldin Index\n",
    "davies_bouldin = davies_bouldin_score(X, labels)\n",
    "print(f\"Davies-Bouldin Index: {davies_bouldin}\")\n",
    "\n",
    "# Inertia (from KMeans)\n",
    "inertia = kmeans.inertia_\n",
    "print(f\"Inertia: {inertia}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
